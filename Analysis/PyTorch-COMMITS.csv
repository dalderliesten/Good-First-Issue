First Commit Pull Request,Related to a good-first-issue?,Developer Experience?,Link to PR,Bug Fix (0/1),Enhancing an Existing Feature (0/1),New Feature (0/1),Documentation(0/1),Testing (0/1),Refactoring (0/1),Other Information
static libraries no longer built by default ,0,Experienced,https://github.com/pytorch/pytorch/commit/35c2754c88896c7742d7bc7e59e1936f19f04776,0,0,0,0,0,1,
Fix class torch.nn.ConvTransposeNd documentation,0,Experienced,https://github.com/pytorch/pytorch/pull/739,0,0,0,1,0,0,
"[cutorch refactor] move meanall function into generic/, update cwrap",0,Experienced,https://github.com/pytorch/pytorch/commit/c2e3bf214547b76682db5ba666a1e75596ec05d1,0,0,0,0,0,1,
caffe2/caffe2/operators/softmax_with_loss_op.cc: avoid shadowing warn,0,Experienced,https://github.com/pytorch/pytorch/commit/6b437708ad8b42a7362178576af0924f3ad6c856,0,0,0,0,0,1,
Fix compilation error when compiling with 'clang -x cuda'. ,0,Experienced,https://github.com/pytorch/pytorch/commit/8241cd7b6ed1425eeb88fd380090575978e358f4,1,0,0,0,0,0,
Missing CUDA_NVCC_FLAGS & CUDA_HOST_COMPILER flags at GPU arch detect,0,Experienced,https://github.com/pytorch/pytorch/commit/b89688658c8c37a3f18071c8a0adb67da2ab1540,1,0,0,0,0,0,
DOC fixed Tensor.expand docstring,0,Experienced,https://github.com/pytorch/pytorch/pull/2495,0,0,0,1,0,0,
fixed #3295,0,Experienced,https://github.com/pytorch/pytorch/pull/3300,1,0,0,0,0,0,
adaptive pooling supports only specifying size in certain dimension,0,Medior,https://github.com/pytorch/pytorch/pull/3127,0,1,0,0,0,0,
Separate parameter downloading tasks from training tasks and run them,0,Experienced,https://github.com/pytorch/pytorch/commit/1d4e996b8712196cc68c0b52c1e7faaa45ddd64b,0,1,0,0,0,1,
Implementing Pow operator (this merges existing pow with a scalar and,0,Experienced,https://github.com/pytorch/pytorch/commit/f7cc8e8822ed641d7a349308bc20b65acc6f7c56,0,0,1,0,0,0,
Fix: gradcheck forced float32,0,Experienced,https://github.com/pytorch/pytorch/pull/8230,1,0,0,0,0,0,
formatting in :math: blocks for fold/unfold docstring,0,Medior,https://github.com/pytorch/pytorch/pull/8696,0,0,0,1,0,0,
#8714 Improve Error Messages for module re-assignment,0,Novice,https://github.com/pytorch/pytorch/pull/9212,0,1,0,0,0,0,
caffe2: UpsampleBilinear support for scales,0,Experienced,https://github.com/pytorch/pytorch/pull/12736,0,1,0,0,0,0,
Make chunk size configurable in SaveOp,0,Novice,https://github.com/pytorch/pytorch/pull/12949,0,1,0,0,0,0,
Fix the bug when compile using nvcc compiler.,0,Medior,https://github.com/pytorch/pytorch/pull/13509,1,0,0,0,0,0,
Corresponding data type for BYTE,0,Experienced,https://github.com/pytorch/pytorch/pull/15627,0,1,0,0,0,0,
SGD: remove unneeded multiply-add initialization operations,0,Experienced,https://github.com/pytorch/pytorch/pull/18114,0,0,0,0,0,1,
Delete unnecessary file split_types.py,0,Medior,https://github.com/pytorch/pytorch/pull/23754,0,0,0,0,0,1,
tensor_numpy: add missing include header,0,Experienced,https://github.com/pytorch/pytorch/pull/24042,1,0,0,0,0,0,
Enhance Tensor indexSelect performance,0,Novice,https://github.com/pytorch/pytorch/pull/23055,0,1,0,0,0,1,
Enable log_softmax and CrossEntropyLoss for bfloat16,0,Medior,https://github.com/pytorch/pytorch/pull/24457,0,1,0,0,0,0,
Exposing Fused8BitRowwiseQuantizedToFloat in PyTorch,0,Medior,https://github.com/pytorch/pytorch/pull/26080,0,0,0,0,0,1,
Removes floating_dtype decorator from test_torch and test_cuda,0,Medior,https://github.com/pytorch/pytorch/pull/27599,0,0,0,0,1,0,
adding python all_gather coalesced functionality and testing.,0,Medior,https://github.com/pytorch/pytorch/pull/28634,0,0,1,0,1,0,
Fix typo in documentation,0,Experienced,https://github.com/pytorch/pytorch/pull/29755,0,0,0,1,0,0,
Fix typos,0,Experienced,https://github.com/pytorch/pytorch/pull/30606,0,0,0,1,0,0,
added exception args to the returned error message,0,Experienced,https://github.com/pytorch/pytorch/pull/32693,0,1,0,0,0,0,
dont force msvc /Ox flag which can conflict with /RTC1 in debug config,0,Experienced,https://github.com/pytorch/pytorch/pull/33164,0,0,0,0,0,1,
